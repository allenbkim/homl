{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Visualizing a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # all instances, petal length and width features\n",
    "y = iris.target\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(\n",
    "    tree_clf,\n",
    "    out_file='iris_tree.dot',\n",
    "    feature_names=iris.feature_names[2:],\n",
    "    class_names=iris.target_names,\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Generated decision tree](iris_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Class Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.90740741, 0.09259259]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]]) # Probabilities for each class for a single instance with length=5 and width=1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'versicolor'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names[tree_clf.predict([[5, 1.5]])[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree for Moons dataset\n",
    "## Exercise 7: Train and fine-tune a Decision Tree for the moons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.22633058,  0.65229144],\n",
       "        [-0.17756477,  0.73007452],\n",
       "        [ 0.61244218,  1.16114535],\n",
       "        ...,\n",
       "        [-0.38454732,  0.90153922],\n",
       "        [-1.26379663,  0.49008327],\n",
       "        [-0.59130673,  0.11966608]]), array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make moons dataset\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "moons = make_moons(n_samples=10000, noise=0.4)\n",
    "moons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(moons[0], moons[1], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a basic Decision Tree classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "moons_clf = DecisionTreeClassifier()\n",
    "moons_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.8035\n"
     ]
    }
   ],
   "source": [
    "# Manually evaluate performance\n",
    "num_instances = y_test.shape[0]\n",
    "num_correct = 0\n",
    "\n",
    "for i in range(num_instances):\n",
    "    if moons_clf.predict([X_test[i]]) == y_test[i]:\n",
    "        num_correct += 1\n",
    "\n",
    "print('Accuracy rate:', num_correct / num_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set: 0.8035\n",
      "Score on training: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Built-in evaluation\n",
    "print('Score on test set:', moons_clf.score(X_test, y_test))\n",
    "print('Score on training:', moons_clf.score(X_train, y_train)) # If this is much higher than we're seeing overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for hyperparameter tuning - let's generalize more better!\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth':np.arange(1,11)} # Try out different values of max_depth\n",
    "clf = GridSearchCV(moons_clf, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV score on test: 0.8565\n",
      "GridSearchCV score on train: 0.859125\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Should be closer together\n",
    "print('GridSearchCV score on test:', clf.score(X_test, y_test))\n",
    "print('GridSearchCV score on train:', clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  1,  1,  4,  5,  6,  3,  7,  8,  9], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which values 1-10 performed best?\n",
    "clf.cv_results_['rank_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Grow a forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1788: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create 1000 training sets of 100 random examples from the moons dataset\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "shuffleSplit = ShuffleSplit(n_splits=1000, train_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1000 decision trees based off the mini datasets\n",
    "\n",
    "decisionTrees = []\n",
    "\n",
    "for train_indices, _ in shuffleSplit.split(moons[0]):\n",
    "    small_X = []\n",
    "    small_y = []\n",
    "    \n",
    "    small_clf = DecisionTreeClassifier()\n",
    "    \n",
    "    for train_index in train_indices:\n",
    "        small_X.append(moons[0][train_index])\n",
    "        small_y.append(moons[1][train_index])\n",
    "        \n",
    "    small_clf.fit(small_X, small_y)\n",
    "    decisionTrees.append(small_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8695\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with each mini decision tree\n",
    "\n",
    "correct_predictions = 0\n",
    "num_test = len(X_test)\n",
    "\n",
    "for i in range(num_test):\n",
    "    prediction = 0\n",
    "    pred_count = 0\n",
    "    \n",
    "    for decisionTree in decisionTrees:\n",
    "        pred_count += decisionTree.predict([X_test[i]])[0]\n",
    "    \n",
    "    if pred_count >= len(decisionTrees) / 2:\n",
    "        prediction = 1\n",
    "    \n",
    "    if prediction == y_test[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "print('Accuracy:', correct_predictions/num_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
